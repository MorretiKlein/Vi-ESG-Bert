{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-02T02:30:37.970878Z",
     "start_time": "2022-06-02T02:30:34.740917Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from transformers import BertTokenizer, Trainer, BertForSequenceClassification, TrainingArguments\n",
    "from transformers import ElectraTokenizer, ElectraForSequenceClassification\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from trl import SFTTrainer\n",
    "import os,torch, wandb, platform, gradio, warnings\n",
    "from pyvi import ViTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-02T02:45:07.491364Z",
     "start_time": "2022-06-02T02:45:07.482746Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.7.0+cu118', '4.51.3')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "torch.__version__, transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-02T02:44:18.286115Z",
     "start_time": "2022-06-02T02:44:18.222850Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-02T02:54:06.431016Z",
     "start_time": "2022-06-02T02:54:06.391735Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thêm dấu phẩy sau trên 700 nghìn tỷ đồng vốn đ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lựa chọn cổ phiếu niêm yết có chỉ số PB cao đư...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chính sách bảo hiểm nông nghiệp là tia hy vọng...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ngoài ra Vingroup cam kết phát triển các dự án...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Diện tích trồng cà gai leo tại địa phương là k...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37631</th>\n",
       "      <td>Chúng tôi là một trong những công ty Thụy Sĩ đ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37632</th>\n",
       "      <td>Chúng ta sẽ đạt được mục tiêu này bằng cách tr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37633</th>\n",
       "      <td>Điều này có nghĩa là cải thiện hiệu quả điện n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37634</th>\n",
       "      <td>Năm 2021 chúng tôi đã tiến hành bước đầu tiên ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37635</th>\n",
       "      <td>Mục đích là để khai thác tiềm năng của chính c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37636 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentences  labels\n",
       "0      Thêm dấu phẩy sau trên 700 nghìn tỷ đồng vốn đ...       0\n",
       "1      Lựa chọn cổ phiếu niêm yết có chỉ số PB cao đư...       0\n",
       "2      Chính sách bảo hiểm nông nghiệp là tia hy vọng...       2\n",
       "3      Ngoài ra Vingroup cam kết phát triển các dự án...       2\n",
       "4      Diện tích trồng cà gai leo tại địa phương là k...       1\n",
       "...                                                  ...     ...\n",
       "37631  Chúng tôi là một trong những công ty Thụy Sĩ đ...       1\n",
       "37632  Chúng ta sẽ đạt được mục tiêu này bằng cách tr...       1\n",
       "37633  Điều này có nghĩa là cải thiện hiệu quả điện n...       1\n",
       "37634  Năm 2021 chúng tôi đã tiến hành bước đầu tiên ...       1\n",
       "37635  Mục đích là để khai thác tiềm năng của chính c...       1\n",
       "\n",
       "[37636 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_train = \"data_pseudo_vireport/train_data_high.csv\"\n",
    "filename_test = \"data_pseudo_vireport/final_test.csv\"\n",
    "\n",
    "data_train = pd.read_csv(filename_train)\n",
    "data_test = pd.read_csv(filename_test)\n",
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "2    14155\n",
       "0     9511\n",
       "3     8203\n",
       "1     5767\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "2    996\n",
       "3    924\n",
       "1    570\n",
       "0    510\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load FinBERT pretrained model\n",
    "The pretrained FinBERT model path on Huggingface is https://huggingface.co/yiyanghkust/finbert-pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-02T02:54:17.945203Z",
     "start_time": "2022-06-02T02:54:10.422200Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at NlpHUST/vi-electra-small and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ElectraForSequenceClassification(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(62000, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (embeddings_project): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): ElectraClassificationHead(\n",
       "    (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (activation): GELUActivation()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=256, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "tokenizer = ElectraTokenizer.from_pretrained('NlpHUST/vi-electra-small')\n",
    "model = ElectraForSequenceClassification.from_pretrained('NlpHUST/vi-electra-small',num_labels=4)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for param in model.bert.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# Keep only the classification head trainable\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-02T02:37:33.687054Z",
     "start_time": "2022-06-02T02:37:33.664650Z"
    }
   },
   "source": [
    "### prepare dataset for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-02T02:54:33.660010Z",
     "start_time": "2022-06-02T02:54:17.948143Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00f39f5b497445a2bdd54ae5b91e37c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/37636 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3573c090c47e4406a93a332f0babcdb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/37636 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = simple_preprocess(text)\n",
    "    # Ghép lại thành câu\n",
    "    text = ' '.join(tokens)\n",
    "    # Tách từ kiểu tiếng Việt (giữ định dạng từ ghép có dấu gạch dưới)\n",
    "    text = ViTokenizer.tokenize(text)\n",
    "    return text\n",
    "\n",
    "# Tiền xử lý cột văn bản trong từng DataFrame\n",
    "data_train['Sentences'] = data_train['Sentences'].apply(preprocess_text)\n",
    "data_test['Sentences'] = data_test['Sentences'].apply(preprocess_text)\n",
    "\n",
    "# Chuyển sang Dataset của HuggingFace\n",
    "dataset_train = Dataset.from_pandas(data_train)\n",
    "dataset_val = Dataset.from_pandas(data_train)\n",
    "\n",
    "\n",
    "dataset_train = dataset_train.map(lambda e: tokenizer(e['Sentences'], truncation=True, padding='max_length', max_length=128), batched=True)\n",
    "dataset_val = dataset_val.map(lambda e: tokenizer(e['Sentences'], truncation=True, padding='max_length', max_length=128), batched=True)\n",
    "\n",
    "dataset_train.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
    "dataset_val.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Sentences', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 37636\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape: torch.Size([32, 128])\n",
      "Labels shape: torch.Size([32])\n",
      "tensor(3)\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "from torch.utils.data import DataLoader\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "# Tạo DataLoader\n",
    "train_dataloader = DataLoader(\n",
    "    dataset_train, \n",
    "    batch_size=32, \n",
    "    collate_fn=data_collator,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Kiểm tra kích thước batch\n",
    "for batch in train_dataloader:\n",
    "    print(\"Input IDs shape:\", batch[\"input_ids\"].shape)\n",
    "    print(\"Labels shape:\", batch[\"labels\"].shape)\n",
    "    print((batch[\"labels\"][0]))\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define training options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/pc/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtrung235689\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.1s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/pc/Code/ESG code/VietNam FinBert/wandb/run-20250612_165902-2gos5yzk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/trung235689/viELECTRA/runs/2gos5yzk?apiKey=e7056d3a3bc855a6e0d38b8c4ff7d2ec7ce895af' target=\"_blank\">mild-snowflake-2</a></strong> to <a href='https://wandb.ai/trung235689/viELECTRA?apiKey=e7056d3a3bc855a6e0d38b8c4ff7d2ec7ce895af' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/trung235689/viELECTRA?apiKey=e7056d3a3bc855a6e0d38b8c4ff7d2ec7ce895af' target=\"_blank\">https://wandb.ai/trung235689/viELECTRA?apiKey=e7056d3a3bc855a6e0d38b8c4ff7d2ec7ce895af</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/trung235689/viELECTRA/runs/2gos5yzk?apiKey=e7056d3a3bc855a6e0d38b8c4ff7d2ec7ce895af' target=\"_blank\">https://wandb.ai/trung235689/viELECTRA/runs/2gos5yzk?apiKey=e7056d3a3bc855a6e0d38b8c4ff7d2ec7ce895af</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Do NOT share these links with anyone. They can be used to claim your runs."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.login(key=\"e7056d3a3bc855a6e0d38b8c4ff7d2ec7ce895af\")\n",
    "run = wandb.init(project='viELECTRA', job_type=\"training\", anonymous=\"allow\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(model.config.num_labels)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-02T02:57:15.963784Z",
     "start_time": "2022-06-02T02:54:33.662575Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11770' max='11770' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11770/11770 23:40, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.161600</td>\n",
       "      <td>0.223027</td>\n",
       "      <td>0.934956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.158100</td>\n",
       "      <td>0.151643</td>\n",
       "      <td>0.953157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.160600</td>\n",
       "      <td>0.130092</td>\n",
       "      <td>0.960517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.173600</td>\n",
       "      <td>0.159131</td>\n",
       "      <td>0.949968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.177700</td>\n",
       "      <td>0.068444</td>\n",
       "      <td>0.980710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.186700</td>\n",
       "      <td>0.087156</td>\n",
       "      <td>0.971782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.171600</td>\n",
       "      <td>0.084879</td>\n",
       "      <td>0.972712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.153400</td>\n",
       "      <td>0.048593</td>\n",
       "      <td>0.986795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.142300</td>\n",
       "      <td>0.049574</td>\n",
       "      <td>0.985891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.135400</td>\n",
       "      <td>0.050178</td>\n",
       "      <td>0.985785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=11770, training_loss=0.16118919288291705, metrics={'train_runtime': 1420.2293, 'train_samples_per_second': 264.999, 'train_steps_per_second': 8.287, 'total_flos': 2768242574745600.0, 'train_loss': 0.16118919288291705, 'epoch': 10.0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {'accuracy' : accuracy_score(predictions, labels)}\n",
    "\n",
    "args = TrainingArguments(\n",
    "        output_dir = 'temp/',\n",
    "        eval_strategy = 'epoch',\n",
    "        save_strategy = 'epoch',\n",
    "        learning_rate= 2e-5,\n",
    "        per_device_train_batch_size=32,\n",
    "        per_device_eval_batch_size=32,\n",
    "        num_train_epochs=10,  # 1 epoch\n",
    "        weight_decay=0.005,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model='accuracy',\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "        model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
    "        args=args,                  # training arguments, defined above\n",
    "        train_dataset=dataset_train,         # training dataset\n",
    "        eval_dataset=dataset_val,            # evaluation dataset\n",
    "        compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### evaluate on testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-02T03:09:08.434635Z",
     "start_time": "2022-06-02T03:09:06.980671Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.04859252646565437,\n",
       " 'test_accuracy': 0.9867945584015304,\n",
       " 'test_runtime': 32.0251,\n",
       " 'test_samples_per_second': 1175.205,\n",
       " 'test_steps_per_second': 36.752}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "trainer.predict(dataset_val).metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-02T03:09:11.599174Z",
     "start_time": "2022-06-02T03:09:10.847115Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving vocabulary to ./VIELECTRA_train/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./VIELECTRA_train/tokenizer_config.json',\n",
       " './VIELECTRA_train/special_tokens_map.json',\n",
       " './VIELECTRA_train/vocab.txt',\n",
       " './VIELECTRA_train/added_tokens.json')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model('VIELECTRA_train/')\n",
    "tokenizer.save_pretrained(\"./VIELECTRA_train/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Class  Accuracy\n",
      "0     0  0.977605\n",
      "1     1  0.994625\n",
      "2     2  0.992441\n",
      "3     3  0.982202\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "predictions = trainer.predict(dataset_val)\n",
    "preds = np.argmax(predictions.predictions, axis=1)\n",
    "labels = predictions.label_ids\n",
    "\n",
    "# --- 9. Hàm tính accuracy theo từng lớp ---\n",
    "def save_per_class_accuracy(y_true, y_pred, class_names=None, output_path=\"viELECTRA_per_class_accuracy.csv\"):\n",
    "    if isinstance(y_true, torch.Tensor):\n",
    "        y_true = y_true.cpu().numpy()\n",
    "    if isinstance(y_pred, torch.Tensor):\n",
    "        y_pred = y_pred.cpu().numpy()\n",
    "\n",
    "    labels = np.unique(y_true)\n",
    "    acc_per_class = []\n",
    "\n",
    "    for label in labels:\n",
    "        idx = y_true == label\n",
    "        acc = accuracy_score(y_true[idx], y_pred[idx])\n",
    "        class_label = class_names[label] if class_names else f\"Class {label}\"\n",
    "        acc_per_class.append((class_label, acc))\n",
    "\n",
    "    df = pd.DataFrame(acc_per_class, columns=[\"Class\", \"Accuracy\"])\n",
    "    print(df)\n",
    "    df.to_csv(output_path, index=False)\n",
    "\n",
    "# --- 10. Gọi hàm ---\n",
    "class_names = [\"0\", \"1\", \"2\", \"3\"]  # bạn có thể thay bằng tên thật của từng lớp nếu có\n",
    "save_per_class_accuracy(labels, preds, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9867945584015304"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "overall_accuracy = accuracy_score(labels, preds)\n",
    "overall_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
